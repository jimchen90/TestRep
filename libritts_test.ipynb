{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchaudio.datasets.utils import (\n",
    "    download_url,\n",
    "    extract_archive,\n",
    "    walk_files,\n",
    ")\n",
    "\n",
    "URL = \"train-clean-100\"\n",
    "FOLDER_IN_ARCHIVE = \"LibriTTS\"\n",
    "_CHECKSUMS = {\n",
    "    \"http://www.openslr.org/60/dev-clean.tar.gz\": \"0c3076c1e5245bb3f0af7d82087ee207\",\n",
    "    \"http://www.openslr.org/60/dev-other.tar.gz\": \"815555d8d75995782ac3ccd7f047213d\",\n",
    "    \"http://www.openslr.org/60/test-clean.tar.gz\": \"7bed3bdb047c4c197f1ad3bc412db59f\",\n",
    "    \"http://www.openslr.org/60/test-other.tar.gz\": \"ae3258249472a13b5abef2a816f733e4\",\n",
    "    \"http://www.openslr.org/60/train-clean-100.tar.gz\": \"4a8c202b78fe1bc0c47916a98f3a2ea8\",\n",
    "    \"http://www.openslr.org/60/train-clean-360.tar.gz\": \"a84ef10ddade5fd25df69596a2767b2d\",\n",
    "    \"http://www.openslr.org/60/train-other-500.tar.gz\": \"7b181dd5ace343a5f38427999684aa6f\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_libritts_item(\n",
    "    fileid: str,\n",
    "    path: str,\n",
    "    ext_audio: str,\n",
    "    ext_original_txt: str,\n",
    "    ext_normalized_txt: str,\n",
    ") -> Tuple[Tensor, int, str, str, int, int, str]:\n",
    "    speaker_id, chapter_id, segment_id, utterance_id = fileid.split(\"_\")\n",
    "    utterance_id = fileid\n",
    "\n",
    "    normalized_text = utterance_id + ext_normalized_txt\n",
    "    normalized_text = os.path.join(path, speaker_id, chapter_id, normalized_text)\n",
    "\n",
    "    original_text = utterance_id + ext_original_txt\n",
    "    original_text = os.path.join(path, speaker_id, chapter_id, original_text)\n",
    "\n",
    "    file_audio = utterance_id + ext_audio\n",
    "    file_audio = os.path.join(path, speaker_id, chapter_id, file_audio)\n",
    "\n",
    "    # Load audio\n",
    "    waveform, sample_rate = torchaudio.load(file_audio)\n",
    "\n",
    "    # Load original text\n",
    "    with open(original_text) as ft:\n",
    "        original_text = ft.readline()\n",
    "\n",
    "    # Load normalized text\n",
    "    with open(normalized_text, \"r\") as ft:\n",
    "        normalized_text = ft.readline()\n",
    "\n",
    "    return (\n",
    "        waveform,\n",
    "        sample_rate,\n",
    "        original_text,\n",
    "        normalized_text,\n",
    "        int(speaker_id),\n",
    "        int(chapter_id),\n",
    "        utterance_id,\n",
    "    )\n",
    "\n",
    "\n",
    "class LIBRITTS(Dataset):\n",
    "    \"\"\"\n",
    "    Create a Dataset for LibriTTS. Each item is a tuple of the form:\n",
    "    waveform, sample_rate, original_text, normalized_text, speaker_id, chapter_id, utterance_id\n",
    "    \"\"\"\n",
    "\n",
    "    _ext_original_txt = \".original.txt\"\n",
    "    _ext_normalized_txt = \".normalized.txt\"\n",
    "    _ext_audio = \".wav\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        url: str = URL,\n",
    "        folder_in_archive: str = FOLDER_IN_ARCHIVE,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        if url in [\n",
    "            \"dev-clean\",\n",
    "            \"dev-other\",\n",
    "            \"test-clean\",\n",
    "            \"test-other\",\n",
    "            \"train-clean-100\",\n",
    "            \"train-clean-360\",\n",
    "            \"train-other-500\",\n",
    "        ]:\n",
    "\n",
    "            ext_archive = \".tar.gz\"\n",
    "            base_url = \"http://www.openslr.org/resources/60/\"\n",
    "\n",
    "            url = os.path.join(base_url, url + ext_archive)\n",
    "\n",
    "        basename = os.path.basename(url)\n",
    "        archive = os.path.join(root, basename)\n",
    "\n",
    "        basename = basename.split(\".\")[0]\n",
    "        folder_in_archive = os.path.join(folder_in_archive, basename)\n",
    "\n",
    "        self._path = os.path.join(root, folder_in_archive)\n",
    "\n",
    "        if download:\n",
    "            if not os.path.isdir(self._path):\n",
    "                if not os.path.isfile(archive):\n",
    "                    checksum = _CHECKSUMS.get(url, None)\n",
    "                    download_url(url, root, hash_value=checksum)\n",
    "                extract_archive(archive)\n",
    "\n",
    "        walker = walk_files(\n",
    "            self._path, suffix=self._ext_audio, prefix=False, remove_suffix=True\n",
    "        )\n",
    "        self._walker = list(walker)\n",
    "\n",
    "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, str, int, int, str]:\n",
    "        fileid = self._walker[n]\n",
    "        return load_libritts_item(\n",
    "            fileid,\n",
    "            self._path,\n",
    "            self._ext_audio,\n",
    "            self._ext_original_txt,\n",
    "            self._ext_normalized_txt,\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._walker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a8368feadb47349699fe84ab41d46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=924804676.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "libritts = LIBRITTS(root = '',\n",
    "                   url = 'dev-other',\n",
    "                   download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0015, -0.0015, -0.0016,  ...,  0.0002,  0.0002,  0.0002]]),\n",
       " 24000,\n",
       " 'This tightened the loop and prevented it from slipping off.',\n",
       " 'This tightened the loop and prevented it from slipping off.',\n",
       " 6841,\n",
       " 88291,\n",
       " '6841_88291_000008_000003')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libritts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
